---
title: "Gamma Distribtuion Method"
output: html_document
---

```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
library(purrr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(zoo)
library(forecast)
library(tibble)

BASE <- "C:/Users/dorh012/Documents/hector-SA-npar/"
INT_OUTPUT_DIR <- paste0(BASE, 'int-out/', 'rcp26')

# Dn_func: is a function that will calculate the Dn distance stat for an observation and model 
# comparison. The input data table requires the run_name, observational and model data, and a 
# s2n column that contains a sample size variability. 

Dn_func <- function(data){
  
  # Check for required columns
  req_columns <- c('run_name', 'obs', 'model', 's2n')
  if( any(!req_columns %in% names(data)) ){stop("Missing 1 or more required columns.")}
  
  # Calculate Dn 
  n  <- nrow(data)
  Dn <- (1 / n) * sum( ( (data[['obs']] - data[['model']]) ^2 ) / data[['s2n']])
  
  # Return Dn as a tibble
  run_name <- unique(data$run_name)
  tibble(run_name = run_name, Dn = Dn)
  
}

# 2. Import Dn input tables ----------------------------------------------------------------
# Import the various Dn files that were created in part G.

path <- list.files(INT_OUTPUT_DIR, "G.mean_Tgav_Dn_input_table.csv", full.names = T)
Tgav_Dn_input <- read.csv(path, stringsAsFactors = FALSE)

path <- list.files(INT_OUTPUT_DIR, "G.NOAA_CO2_Dn_input_table.csv", full.names = T)
CO2_Dn_input <- read.csv(path, stringsAsFactors = FALSE)

path <- list.files(INT_OUTPUT_DIR, "G.CDIAC_LandFlux_Dn_input_table.csv", full.names = T)
LandFlux_Dn_input <- read.csv(path, stringsAsFactors = FALSE)


# 3. Get Dn ------------------------------------------------------------------------------
Tgav_Dn_input %>%  
  split(.$run_name) %>% 
  # Find the Dn for every single run_name by mapping the Dn_func to every
  # run_name data frame.
  map(., function(data = .){ Dn_func(data) }) %>% 
  bind_rows -> 
  Tgav_Dn

CO2_Dn_input %>% 
  split(.$run_name) %>% 
  map(., function(data = .){ Dn_func(data) }) %>% 
  bind_rows -> 
  CO2_Dn

LandFlux_Dn_input %>% 
  split(.$run_name) %>% 
  map(., function(data = .){ Dn_func(data) }) %>% 
  bind_rows -> 
  LandFlux_Dn

```



### Context


So on May 21 we met and discussed using the ${D}_{n}$ metric for the CMS project but were struggling with how to construct the $\gamma$ distribution to find ${D}_{c}$ the cut off value for ${D}_{n}$. 

Bottom of page 2969 from the SEA ICE paper covers background on the $\gamma$ distribution. Page 2931 talks about how they implemented it and stresses how important the $\sigma_{O-M}^2$ is for the $\gamma$ distribution. 

We decided we wanted $\sigma_{O-M}^2$ to be the variability in the observation residuals when the observations were detrended using a linear regression. I am not 100 % sure that this is what we want to do so I have been playing a round with some different methods and this document walks through the things I tired. 



### Linear Detrending

Use a linear regression to detrend the observational data. I am not supper excited about this method, I only found one paper [link](https://www.researchgate.net/figure/Atmospheric-CO2-data-deseasonalized-and-detrended-monthly-means-1958-2015_fig3_283119339) that uses this method and it doesn't look great. Only one author and has never been cited. 


```{r, echo = FALSE}

temp_obs <- filter(Tgav_Dn_input, run_name == 'hectorSA-0001')


#plot(temp_obs$year, temp_obs$obs, xlab = 'time', ylab = 'temp')
rslt <- lm(temp_obs$obs ~ temp_obs$year)
fit  <- temp_obs$year * coef(rslt)[[2]] + coef(rslt)[[1]]

resd <- temp_obs$obs - fit

qplot(temp_obs$year, resd, ylab = 'detrended temp', xlab = 'year')

```

So then if we use this variance we get the following distribution. 

```{r, echo = F}

# Get the dsitribtuion using the varience of the linear detrended residuals
n          <- nrow(temp_obs)
a          <- n / 2
sigma_diff <- var(resd)

b <- (1/n^2) * sum(sigma_diff / temp_obs[['s2n']])

Dn_v <- seq(from = 0, to = 150, length.out = 1000)

gamma <- dgamma(Dn_v, shape = a, scale = b)
temp_Dc <- qgamma(.95, shape = a, scale = b)
  
tibble::tibble(Dn = Dn_v, gamma = gamma) %>%
  ggplot() + 
  geom_line(aes(x = Dn, y = gamma)) + 
  labs(title = 'Temp Linear Detrending Distribution', 
       caption = paste0('sigma = ', sigma_diff, '\n Dc = ', temp_Dc)) + 
  coord_cartesian(xlim = c(0, 20)) 

```
 
 So using this method we have... 

```{r, echo = FALSE}
Tgav_Dn %>%  
  filter(Dn < temp_Dc) %>% 
  nrow
```

... that are considered to be matching.


***

For CO2 we shouldn't use a linear regression, I tried transforming the data but that did not work and to use a non linear solver we need some idea of what the non linear equation is. 
 
 

```{r, echo = F}
# 
# rslt <- lm(log(CO2_obs$obs) ~ CO2_obs$year)
# fit  <- CO2_obs$year * coef(rslt)[[2]] + coef(rslt)[[1]]
# 
# resd <- CO2_obs$obs - fit
# 
# # Get the dsitribtuion using the varience of the linear detrended residuals
# n          <- nrow(CO2_obs)
# a          <- n / 2
# sigma_diff <- var(resd)
# 
# b <- (1/n^2) * sum(sigma_diff / temp_obs[['s2n']])
# 
# Dn_v <- seq(from = 0, to = 150, length.out = 1000)
# 
# gamma <- dgamma(Dn_v, shape = a, scale = b)
# CO2_Dc <- qgamma(.95, shape = a, scale = b)
# 
# tibble::tibble(Dn = Dn_v, gamma = gamma) %>%
#   ggplot() +
#   geom_line(aes(x = Dn, y = gamma)) +
#   labs(title = 'Temp Linear Detrending Distribution',
#        caption = paste0('sigma = ', sigma_diff, '\n Dc = ', temp_Dc)) +
#   coord_cartesian(xlim = c(0, 20))

```



### Moving Average Detrending

While the linear detrending method worked okay for temp it was wonky with CO2 so I tried using a moving average method that was used in [link](http://www.pnas.org/content/pnas/110/32/13061.full.pdf) and [link](https://www.tandfonline.com/doi/pdf/10.3402/tellusb.v50i1.16018?needAccess=true)


So the residuals for temp look like ... 

```{e, echo = FALSE}

trend_temp <- ma(temp_obs$obs, order = 3, centre = T)

qplot(x = temp_obs$year, y = temp_obs$obs - trend_temp, geom = 'line') + 
  labs(y = 'temp moving average residual', 
       x = 'year', 
       title = 'Temp moving average residual')

```


With a $\gamma$ distribution that looks like... 

```{r, echo = F}

trend_temp <- ma(temp_obs$obs, order = 10, centre = T)

# Get the dsitribtuion using the varience of the linear detrended residuals
n          <- nrow(temp_obs)
a          <- n / 2
sigma_diff <- (sd(temp_obs$obs - trend_temp, na.rm = T))^2

b <- (2/n) * sum(sigma_diff / temp_obs[['s2n']])
sum((2 * sigma_diff )/ (n * temp_obs[['s2n']]))
#b <-  ((2n * sigma_diff) / (n * mean(temp_obs[['s2n']])))

Dn_v <- seq(from = 0, to = 5, length.out = 1000)

gamma <- dgamma(Dn_v, shape = a, scale = b)
temp_Dc <- qgamma(.95, shape = a, scale = b)
  
tibble::tibble(Dn = Dn_v, gamma = gamma) %>%
  ggplot() + 
  geom_line(aes(x = Dn, y = gamma)) + 
  labs(title = 'Temp moving Average Detrending Distribution', 
       caption = paste0('sigma = ', sigma_diff, '\n Dc = ', temp_Dc)) + 
  coord_cartesian(xlim = c(0, 5)) 

```

So using this method we have... 

```{r, echo = FALSE}
Tgav_Dn %>%  
  filter(Dn < temp_Dc) %>% 
  nrow
```

... that are considered to be matching.


### Rolling SD 

So in the paper they look at the sd in a spatial window. What is we do something similar and look at the sd in a temporal window. This is some what made up so we will see. 

So this was my thought process behind this. 

They did a standard deviation around an area is expected to be close to or related to one another. Similarly we expect the years to be related to another another. Which is why we want $\sigma$ to have some wiggle room so the years can be mismatching a bit. When I first tried to find the $\gamma$ I took the variability over the whole observational period, that included the signal and we saw too many hector runs count as passing. I set $\sigma$ equal to the variance of the detrended observations then the only variance allowed were the wiggles. But we want to relax the criteria so that Hector can be off by the wiggle variability and a bit of the signal, like a lag or something. 

So what if we set $\sigma$ equal to the average sd of some window. In some instances I think we want the sd to be multiplied in some cases we might not. 


So here is our temperature obs data 

```{r, echo = FALSE}
qplot(temp_obs$year, temp_obs$obs, geom = 'line') + 
  labs(x = 'year', 
       y = 'temp', 
       title = 'Temp Obs')

```


Here is our 'rolling sd' time series, so now the sd has a bit of the variability between years and signal variability.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
rolling_sd <- rollapply(temp_obs$obs, width = 5, FUN = function(x){sd(x)}, na.pad = T)
  
qplot(temp_obs$year, rolling_sd, geom = 'line')  + 
  labs(y = 'temp sd', 
       x = 'year', 
       title = 'Rolling SD', 
       caption = "window length = 15")
```



With a $\gamma$ distribution that looks like... 

```{r, echo = F}

CO2_obs <- filter(CO2_Dn_input, run_name == 'hectorSA-0001')

# Get the dsitribtuion using the varience of the linear detrended residuals
n          <- nrow(CO2_obs)
a          <- n / 2
sigma_diff <- mean( 2 * rolling_sd , na.rm = T) ^ 2

b <- (1/n^2) * sum(sigma_diff / temp_obs[['s2n']])

Dn_v <- seq(from = 0, to = 100, length.out = 1000)

gamma <- dgamma(Dn_v, shape = a, scale = b)
temp_Dc <- qgamma(.95, shape = a, scale = b)
  
tibble::tibble(Dn = Dn_v, gamma = gamma) %>%
  ggplot() + 
  geom_line(aes(x = Dn, y = gamma)) + 
  labs(title = 'Temp rolling sd', 
       caption = paste0('sigma = ', sigma_diff, '\n Dc = ', temp_Dc)) 

```


 So using this method we have... 

```{r, echo = FALSE}
Tgav_Dn %>%  
  filter(Dn < temp_Dc) %>% 
  nrow
```

... temp runs that are considered to be matching.



*** 


CO2 



```{r, echo = FALSE, message = FALSE, warning=FALSE}
rolling_sd <- rollapply(CO2_obs$obs, width = 5, FUN = function(x){sd(x)}, na.pad = T)
  
qplot(CO2_obs$year, rolling_sd, geom = 'line')  + 
  labs(y = 'CO2 sd', 
       x = 'year', 
       title = 'Rolling SD', 
       caption = "window length = 5")
```



With a $\gamma$ distribution that looks like... 

```{r, echo = F}

CO2_obs <- filter(CO2_Dn_input, run_name == 'hectorSA-0001')

# Get the dsitribtuion using the varience of the linear detrended residuals
n          <- nrow(CO2_obs)
a          <- n / 2
sigma_diff <- mean( 2 * rolling_sd , na.rm = T) ^ 2

b <- (1/n^2) * sum(sigma_diff / CO2_obs[['s2n']])

Dn_v <- seq(from = 0, to = 6, length.out = 100)

gamma <- dgamma(Dn_v, shape = a, scale = b)
CO2_Dc <- qgamma(.95, shape = a, scale = b)
  
tibble::tibble(Dn = Dn_v, gamma = gamma) %>%
  ggplot() + 
  geom_line(aes(x = Dn, y = gamma)) + 
  labs(title = 'CO2 rolling sd', 
       caption = paste0('sigma = ', sigma_diff, '\n Dc = ', CO2_Dc)) 

```


 So using this method we have... 

```{r, echo = FALSE}
CO2_Dn %>%  
  filter(Dn < CO2_Dc) %>% 
  nrow
```

... CO2 runs that are considered to be matching.


*** 

Land Flux 




```{r, echo = FALSE, message = FALSE, warning=FALSE}

LandFlux_obs <- filter(LandFlux_Dn_input, run_name == 'hectorSA-0001')


rolling_sd <- rollapply(LandFlux_obs$obs, width = 5, FUN = function(x){sd(x)}, na.pad = T)
  
qplot(LandFlux_obs$year, rolling_sd, geom = 'line')  + 
  labs(y = 'LandFlux sd', 
       x = 'year', 
       title = 'Rolling SD', 
       caption = "window length = 5")
```



With a $\gamma$ distribution that looks like... 

```{r, echo = F}

# Get the dsitribtuion using the varience of the linear detrended residuals
n          <- nrow(LandFlux_obs)
a          <- n / 2
sigma_diff <- mean( 2 * rolling_sd , na.rm = T) ^ 2

b <- (1/n^2) * sum(sigma_diff / LandFlux_obs[['s2n']])

Dn_v <- seq(from = 0, to = 6, length.out = 100)

gamma <- dgamma(Dn_v, shape = a, scale = b)
LandFlux_Dc <- qgamma(.95, shape = a, scale = b)
  
tibble::tibble(Dn = Dn_v, gamma = gamma) %>%
  ggplot() + 
  geom_line(aes(x = Dn, y = gamma)) + 
  labs(title = 'Land Flux rolling sd', 
       caption = paste0('sigma = ', sigma_diff, '\n Dc = ', LandFlux_Dc)) 

```


 So using this method we have... 

```{r, echo = FALSE}
LandFlux_Dn %>%  
  filter(Dn < LandFlux_Dc) %>% 
  nrow
```

... CO2 runs that are considered to be matching.



***
So this method has runs passing but there are lots of subjective decisions to be made, like how big the rolling sd window is can alter $D_{c}$ quite a bit. Or if we multiply the sd to make it larger. 



#### Conclusions 

- If we have an idea about what non linear fit works with CO2 may be we can do the linear detrending method 
- Probably not the moving average detrending method 
- May be the rolling sd method but I am not sure... what are your thoughts?
_ Email the people from the sea ice paper? 
